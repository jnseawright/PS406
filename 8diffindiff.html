<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>8: Difference-in-Differences Designs</title>
    <meta charset="utf-8" />
    <meta name="author" content="J. Seawright" />
    <meta name="date" content="2024-05-13" />
    <script src="8diffindiff_files/header-attrs-2.25/header-attrs.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# 8: Difference-in-Differences Designs
]
.subtitle[
## Quantitative Causal Inference
]
.author[
### <large>J. Seawright</large>
]
.institute[
### <small>Northwestern Political Science</small>
]
.date[
### May 13, 2024
]

---

class: center, middle

&lt;style type="text/css"&gt;
pre {
  max-height: 400px;
  overflow-y: auto;
}

pre[class] {
  max-height: 200px;
}
&lt;/style&gt;




---
### Before and After

Do we need over-time comparisons to achieve causal inference? Do they help? How?

### Before and After

Suppose we have a set of confounders that:

1. Varies across cases but is fixed over time, and/or

2. Is completely shared across cases but varies over time.

---
### Difference-In-Differences

`\(Y_{0,i,t}\)` and `\(Y_{1,i,t}\)`

---
### Difference-In-Differences

`\([Y_{1,i,t+k} - Y_{0,i,t+k}] - [Y_{0,j,t} - Y_{0,j,t}]\)`

---
&lt;img src="images/miamiboatlift.JPG" width="90%" style="display: block; margin: auto;" /&gt;

---
&lt;img src="images/mariel1.JPG" width="90%" style="display: block; margin: auto;" /&gt;

---
&lt;img src="images/mariel2.JPG" width="90%" style="display: block; margin: auto;" /&gt;

---
&lt;img src="images/marielcomparison.JPG" width="90%" style="display: block; margin: auto;" /&gt;

---
&lt;img src="images/marielcomparison2.JPG" width="90%" style="display: block; margin: auto;" /&gt;

---
&lt;img src="images/marielconclusions.JPG" width="90%" style="display: block; margin: auto;" /&gt;

---
### Analysis

Starting simple, if we think *all* the confounding variables are constant either in time or space, then the model we want may be something like:

`$$y_{i,t} = \alpha_{i} + \gamma_{t} + \beta_{1}Treatment_{i,t} + \epsilon_{i,t}$$`

---

```r
library(causaldata)
od &lt;- causaldata::organ_donations
library(fixest)
```

---

```r
# Treatment variable
od &lt;- od %&gt;%
    mutate(Treated = State == 'California' &amp; 
              Quarter %in% c('Q32011','Q42011','Q12012'))

clfe &lt;- feols(Rate ~ Treated | State + Quarter,
               data = od)
```

---

```r
summary(clfe)
```

```
## OLS estimation, Dep. Var.: Rate
## Observations: 162 
## Fixed-effects: State: 27,  Quarter: 6
## Standard-errors: Clustered (State) 
##              Estimate Std. Error  t value  Pr(&gt;|t|)    
## TreatedTRUE -0.022459   0.006131 -3.66304 0.0011185 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## RMSE: 0.021982     Adj. R2: 0.974196
##                  Within R2: 0.009221
```

---
### Parallel Trends

The analysis here assumes that the treatment and control cases have *parallel time trends* on the dependent variable, conditional on any control variables and other adjustments in the model.

---
&lt;img src="images/parallel1.png" width="80%" style="display: block; margin: auto;" /&gt;

---
&lt;img src="images/parallel2.png" width="80%" style="display: block; margin: auto;" /&gt;

---
### Parallel Trends

One useful test is to statistically test whether the treatment and control group had equal time trends during the period before the treatment. If we fit a model that estimates separate time slopes for the two groups, and then we test for equality between those two slopes, that is one way of testing the parallel trends assumption. 

---

```r
od$calind &lt;- 1*(od$State=='California')
odparalleltrends.lm &lt;- lm(Rate~Quarter_Num+Quarter_Num:calind, data=od[od$Quarter_Num&lt;4,])
summary(odparalleltrends.lm)
```

```
## 
## Call:
## lm(formula = Rate ~ Quarter_Num + Quarter_Num:calind, data = od[od$Quarter_Num &lt; 
##     4, ])
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.31778 -0.11098  0.00612  0.11568  0.32600 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)         0.433635   0.046060   9.415  1.7e-14 ***
## Quarter_Num         0.005181   0.021380   0.242   0.8092    
## Quarter_Num:calind -0.074189   0.042673  -1.739   0.0861 .  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.1567 on 78 degrees of freedom
## Multiple R-squared:  0.03746,	Adjusted R-squared:  0.01278 
## F-statistic: 1.518 on 2 and 78 DF,  p-value: 0.2256
```

---

```r
library(interactions)
```

```
## 
## Attaching package: 'interactions'
```

```
## The following objects are masked from 'package:jtools':
## 
##     cat_plot, interact_plot, johnson_neyman, probe_interaction,
##     sim_slopes
```

---

```r
interact_plot(odparalleltrends.lm, pred="Quarter_Num", modx="calind", interval=TRUE)
```

&lt;img src="8diffindiff_files/figure-html/unnamed-chunk-15-1.png" width="70%" style="display: block; margin: auto;" /&gt;

---
### Parallel Trends

If the parallel trends assumption fails, a difference-in-differences design may not be salvageable. It might be possible to control for time trends, but this can subtract out part of the causal effect and produce bias. At this point, a great deal of care and thought is needed, as well as substantial skill with time-series methods.

---
&lt;img src="images/ImaiKimdifndif.png" width="90%" style="display: block; margin: auto;" /&gt;

---
### Negative Weights

Negative weights can emerge in TWFE for difference-in-differences because treated observations of early treatment adopters end up serving as controls for late treatment adopters (see de Chaisemartin and d'Haultfoeuille 2020 and Goodman-Bacon 2021).

---
### Panel Matching

Imai and coauthors propose panel-based matching as a way of implementing difference-in-differences designs. 

---
&lt;img src="images/Shiraef1.png" width="90%" style="display: block; margin: auto;" /&gt;

---
&lt;img src="images/Shiraef2.png" width="90%" style="display: block; margin: auto;" /&gt;

---
&lt;img src="images/Shiraef3.png" width="90%" style="display: block; margin: auto;" /&gt;

---
&lt;img src="images/Liu1.png" width="90%" style="display: block; margin: auto;" /&gt;

---
### Functional Form

`$$Y_{0,i,t}=f(X_{i,t})+h(U_{i,t})+\epsilon_{i,t}$$`

in which `\(f(\cdot)\)` and `\(h(\cdot)\)` are known, parametric functions.

---
### Strict Exogeneity

`$$\epsilon_{i,t} \perp\!\!\!\perp \{D_{j,s},X_{j,s},U_{j,s}\}$$`
for all `\(i,j \in \{1,2,...,N\}\)` and `\(s,t \in \{1,2,...,T\}\)`.

---
### Low-dimensional Decomposition

There  exists  a  low-dimensional  decomposition  of

`$$h(U_{i,t}) : h(U_{i,t}) = L_{i,t}$$`
and `\(rank(L_{NÃ—T}) &lt;&lt; min\{N,T\}\)`.

---
### Estimation

1. Using only untreated observations, model the outcome, based on `\(X\)` and whatever strategy is needed to capture `\(U\)`.

2. Using the model from step 1, form fitted values `\(\hat{Y}_{0,i,t}\)` for each *treated* observation.

3. Estimate the treatment effect for each treated observation by: `\(\hat{\delta}_{i,t} = Y_{i,t} - \hat{Y}_{0,i,t}\)`.

4. Average the `\(\hat{\delta}\)` values to estimate whatever causal quantity is of interest.

---
### Specific Estimators

FEct: estimate `\(\hat{Y}_{0,i,t}\)` using TWFE.

IFEct: estimate `\(\hat{Y}_{0,i,t}\)` using a version of TWFE augmented with a factor-analysis model to allow for existence of limited categories of time-varying unobserved covariates.

Matrix completion: conceptually similar to factor analysis; somewhat different performance properties.

---
&lt;img src="images/Liu2.png" width="90%" style="display: block; margin: auto;" /&gt;

---

```r
library(fect)
```

```
## Registered S3 method overwritten by 'GGally':
##   method from   
##   +.gg   ggplot2
```

---

```r
od$numerictreat &lt;- 1*od$Treated
calfect &lt;- fect(Rate ~ numerictreat, index = c("State", "Quarter_Num"), force = "two-way",
               data = od, se=1)
```

```
## Parallel computing ...
```

```
## Bootstrapping for uncertainties ...
```

```
## 68 runs
```

```
## Cannot use full pre-treatment periods in the F test. The first period is removed.
```

```r
calfect
```

```
## Call:
## fect.formula(formula = Rate ~ numerictreat, data = od, index = c("State", 
##     "Quarter_Num"), force = "two-way", se = 1)
## 
## ATT:
##                                ATT     S.E. CI.lower CI.upper   p.value
## Tr obs equally weighted   -0.02246 0.006184 -0.03458 -0.01034 0.0002813
## Tr units equally weighted -0.02246 0.006184 -0.03458 -0.01034 0.0002813
```

---

```r
calife &lt;- fect(Rate ~ numerictreat, index = c("State", "Quarter_Num"), force = "two-way",
               data = od, method="ife",min.T0=1, se=1)
```

```
## Parallel computing ...
```

```
## Bootstrapping for uncertainties ...
```

```
## 75 runs
```

```
## Cannot use full pre-treatment periods in the F test. The first period is removed.
```

```r
calife
```

```
## Call:
## fect.formula(formula = Rate ~ numerictreat, data = od, index = c("State", 
##     "Quarter_Num"), force = "two-way", method = "ife", se = 1, 
##     min.T0 = 1)
## 
## ATT:
##                                ATT     S.E. CI.lower CI.upper   p.value
## Tr obs equally weighted   -0.02246 0.005181 -0.03261  -0.0123 1.461e-05
## Tr units equally weighted -0.02246 0.005181 -0.03261  -0.0123 1.461e-05
```

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create();
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
